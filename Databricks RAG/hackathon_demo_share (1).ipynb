{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "557869f9-0752-4d9f-add2-868bb7118e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Using Generative AI in your projects\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Query the foundation model APIs\n",
    "    - With the OpenAI client\n",
    "    - With the Databricks GenAI Inference SDK\n",
    "    - With AI SQL functions\n",
    "2. Getting Started with Databricks Vector Search\n",
    "3. RAG: Vector Search + LLMs\n",
    "4. Next steps: LLM Chatbot With Retrieval Augmented Generation (RAG) and DBRX Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aab2ead-60dd-45b4-bcc0-fbc22fa7fec2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Query the Foundation Model APIs\n",
    "- AI playground is useful for comparing models, but we need other approaches to integrating GenAI in our projects\n",
    "- The Foundation Model APIs provide an easy way to use state-of-the-art open models without the need to provision the computational resources yourself.\n",
    "\n",
    "## Using the OpenAI Python SDK\n",
    "- The Foundation Model APIs are compatible with OpenAI's Python client\n",
    "- Easy to switch OpenAI-based projects over to using the Databricks Foundation Model APIs\n",
    "\n",
    "### Setup\n",
    "- Set `OPENAI_BASE_URL` to `your_databricks_workspace_url`/`serving-endpoints`\n",
    "- Set `OPENAI_API_KEY` to a databricks Personal Access Token, which you can obtain from User Settings > Developer > Access Tokens > Generate New Token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8398db49-9388-4184-a702-c0f42d3a340a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "%pip install --upgrade OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b5aab3-01e5-4da5-82c7-e8e54e445a7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c81fe8-ef98-4269-a11f-44c73e666882",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_BASE_URL\"] = \"<your_workspace_url>/serving-endpoints/\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your_personal_access_token>\"\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://adb-3989190133890802.2.azuredatabricks.net/serving-endpoints/databricks-dbrx-instruct/invocations\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-dRl3zkD4w93f9U4qtDYfT3BlbkFJPdqoVMJg6DBDEHFo5du6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc96e58-b409-44dc-977a-9a8f1c3c1bfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"dapi89dbb6f67448e2f0c1e0d1db6ce213d9-3\"\n",
    "\n",
    "DATABRICKS_TOKEN = os.environ.get('DATABRICKS_TOKEN')\n",
    "# Alternatively in a Databricks notebook you can use this:\n",
    "# DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "# client = OpenAI() \n",
    "\n",
    "client = OpenAI(api_key=DATABRICKS_TOKEN,  base_url=\"https://adb-3989190133890802.2.azuredatabricks.net/serving-endpoints\")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"databricks-dbrx-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the relationship between Delta Lake and Parquet?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b75f826-77d3-4b6f-b641-56d7ca38417a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=\"https://adb-3989190133890802.2.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an AI assistant\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Tell me about Large Language Models\"\n",
    "  }\n",
    "  ],\n",
    "  model=\"databricks-dbrx-instruct\",\n",
    "  max_tokens=256\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca656b7-1de6-44c7-8ad0-d2f4451a3d1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI, APIError\n",
    "# client = OpenAI()\n",
    "\n",
    "try:\n",
    "    client = OpenAI(api_key=\"sk-proj-dRl3zkD4w93f9U4qtDYfT3BlbkFJPdqoVMJg6DBDEHFo5du6\", base_url = \"https://api.openai.com\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the relationship between Delta Lake and Parquet?\",\n",
    "            },\n",
    "        ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "except APIError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbb67041-2c50-423d-90a8-423ae7614884",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Using the Databricks GenAI SDK\n",
    "- Similar functionality to the OpenAI SDK\n",
    "- Designed for use in Databricks notebooks\n",
    "- Handles authentication automatically\n",
    "- `ChatSession` interface makes it east to manage multi-turn chat exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f336c7f0-6439-4e9c-acf1-55bd9ce5be6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-genai-inference\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b19a1d33-5885-4a1c-bd3b-2cfc013f7a0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Set up the chat session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3411c8-c538-4f73-b5ab-ce0d86c8ea5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_genai_inference import ChatSession\n",
    "\n",
    "chat = ChatSession(\n",
    "    model=\"databricks-dbrx-instruct\", system_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c7010c9-801f-43e6-bf75-2a7a5f61db2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Send a User message to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "951b6224-6b21-4d06-ad54-5f061c08d752",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat.reply(\"What is the relationship between Delta Lake and Parquet?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "406c08a5-16bf-4c7d-af29-b08305bec57f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Get the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "668ae914-20a6-490a-becb-fb28db8b8dbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(chat.last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b925b563-51b7-4611-b952-7be178f1da29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You can keep repeating this procedure to carry on a chat exchange with the model. You can obtain the whole history as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4283b63-6cf8-4eec-b3eb-1f937536fea5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b95cf3ac-15b0-4f33-990a-1f97f48b3024",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There are several more methods to query the foundation model APIs; you can learn more about them [here](https://docs.databricks.com/en/machine-learning/model-serving/score-foundation-models.html). These include:\n",
    "- REST API\n",
    "- MLFlow Deployments SDK\n",
    "- [SQL Functions](https://docs.databricks.com/en/large-language-models/ai-functions.html): these functions use the Foundation Model APIs to accomplish specific tasks such as AI summarization, extraction, and grammar correction. Depending on your project, AI SQL functions might be the best and simplest way for you to use AI!\n",
    "    - ai_analyze_sentiment\n",
    "    - ai_classify\n",
    "    - ai_extract\n",
    "    - ai_fix_grammar\n",
    "    - ai_gen\n",
    "    - ai_mask\n",
    "    - ai_similarity\n",
    "    - ai_summarize\n",
    "    - ai_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5dd5a23-0531-4a5a-b340-cc1dc0338777",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT ai_extract(\n",
    "    'John Doe lives in New York and works for Acme Corp.',\n",
    "    array('person', 'location', 'organization')\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e162012b-276c-41d8-8c61-e762c72a6689",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Using Databricks Vector Search\n",
    "- Examples so far: We send a prompt to the model, and the model generates a response based only on its training data.\n",
    "- Retrieval-Augmented Generation (RAG): *Augment* prompts with information *retrieved* from an outside data source, enabling the model to *generate* responses informed by the retrieved information. Why?\n",
    "    - Access to proprietary or domain-specific information.\n",
    "    - Access to timely information.\n",
    "    - Fine-grained permissions control.\n",
    "\n",
    "## Vector Search\n",
    "- A special type of language model called an *embedding model* translates each of the texts we want to search into a numeric representations called embeddings that capture the meaning of the text\n",
    "- We can efficiently search for similar embeddings, which lets us use natural-language queries to find relevant texts in a vector database.\n",
    "\n",
    "### Databricks Vector Search\n",
    "- Databricks Vector Search is a vector database integrated into the Databricks platform for storing and retrieving embeddings.\n",
    "    - A vector search endpoint is a scalable compute resource that handles API requests to query and update the search index.\n",
    "    - A vector search index is a data structure optimized for efficient similarity search, created from a Delta table. The Delta table provides a reliable and scalable storage format for the original data. The index is a separate data structure that enables fast retrieval of similar vectors.\n",
    "    - The index can be kept in sync with the delta table automatically or manually\n",
    "\n",
    "## Vector Search Demo\n",
    "- Scrape documentation from a website\n",
    "- Split it into chunks\n",
    "- Save it to the Delta table\n",
    "- Synchronize the Delta table with the Vector Search Index\n",
    "- Query the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44767e97-6f43-41e2-86b6-be314952cbfd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37747c84-18c5-4e5f-829e-07695d18faa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade databricks-vectorsearch databricks-genai-inference llama-index llama-index-readers-web\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6194d50a-dde9-4ff7-af80-c4adf1848f93",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Initialize the vector search client:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff406db9-98d3-408e-a08e-cdd975eab0df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a98e651b-fe0c-49cf-8e9f-3fd50ef0882f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Set up a vector search endpoint**\n",
    "- Can use the UI, Python SDK, or REST API\n",
    "- We set up the example endpoint in advance of this demo as it takes a few minutes to provision the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f0d6245-c801-4aa1-8f46-5854792dba44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Create a source Delta table**\n",
    "- Simple example: columns for unique ID and text\n",
    "- Databricks Vector Search also enables searching/filtering on metadata, so you can add more columns for e.g. document title, date, or whatever else you might want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f90b3ab-558a-41be-8c25-92ce5c4a73d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up schema/volume/table\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS genai_exploration.hackathon_demo\")\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS genai_exploration.hackathon_demo.source_table (\n",
    "        id STRING,\n",
    "        text STRING\n",
    "    )\n",
    "    USING delta \n",
    "    TBLPROPERTIES ('delta.enableChangeDataFeed' = 'true')\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efaccbc2-f4e0-42e3-b524-e15707d5f6a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Vector Search client\n",
    "\n",
    "\n",
    "# Create the Vector Search endpoint\n",
    "vsc.create_endpoint(\n",
    "    name=\"rag_demo_endpoint\",\n",
    "    endpoint_type=\"STANDARD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fcffcff-3ddf-40c1-add3-7d6ba291aa68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Create the vector search index**\n",
    "- to save time, we created the index in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "527c8d76-f805-40c6-a6f2-bcb7ca907334",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index=vsc.create_delta_sync_index(\n",
    "    endpoint_name=\"rag_demo_endpoint\",\n",
    "    index_name=\"genai_exploration.hackathon_demo.vs_index\",\n",
    "    source_table_name=\"genai_exploration.hackathon_demo.source_table\",\n",
    "    pipeline_type=\"CONTINUOUS\", # or TRIGGERED\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column=\"text\",\n",
    "    embedding_model_endpoint_name=\"databricks-bge-large-en\" # or provide an embedding_vector_column\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76c97a03-6d78-43e7-90e1-c012b29254cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Retrieve the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7309b09b-d7d7-45f3-93e4-429e93a94ad9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index = vsc.get_index(\n",
    "    endpoint_name=\"rag_demo_endpoint\",\n",
    "    index_name=\"genai_exploration.hackathon_demo.vs_index\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db8e8e15-2333-4981-8f95-75638a6ce68f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Obtain and process the data:**\n",
    "- Databricks GenAI tools work well with OSS libraries such as LlamaIndex and Langchain.\n",
    "- Here, we use LlamaIndex to obtain, parse, and split the webpage data.\n",
    "- Once we load them to the source Delta table, they will be synchronized with the Vector Search index automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8d49ddc-4dc2-4208-b7b3-d86bd27a2224",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# the URLs we're getting data from\n",
    "urls = [\"https://docs.databricks.com/en/generative-ai/vector-search.html\",\n",
    "        \"https://docs.databricks.com/en/generative-ai/create-query-vector-search.html\",\n",
    "        \"https://docs.databricks.com/en/generative-ai/retrieval-augmented-generation.html\"]\n",
    "\n",
    "# llamaindex tools for getting and splitting the text\n",
    "reader = SimpleWebPageReader(html_to_text=True)\n",
    "parser = SentenceSplitter.from_defaults()\n",
    "\n",
    "# text chunks for indexing\n",
    "chunks = parser.get_nodes_from_documents(reader.load_data(urls))\n",
    "\n",
    "# the schema of our source delta table\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"text\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize an empty DataFrame with the defined schema\n",
    "df = spark.createDataFrame([], schema)\n",
    "\n",
    "# Iterate through the list of chunks\n",
    "for chunk in chunks:\n",
    "    chunk = chunk.dict()\n",
    "    chunk_id = chunk[\"id_\"]\n",
    "    chunk_text = chunk[\"text\"]\n",
    "    \n",
    "    # Create a new row with the extracted properties\n",
    "    new_row = spark.createDataFrame([(chunk_id, chunk_text)], schema)\n",
    "    \n",
    "    # Append the new row to the DataFrame\n",
    "    df = df.union(new_row)\n",
    "\n",
    "# Save the DataFrame as a table\n",
    "df.write.format(\"delta\").mode(\"append\").saveAsTable(\"shared.hackathon_demo.source_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d26baa0d-7fe5-43c4-89a1-a1457479e1d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And now we can query the index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "998c1d6f-2302-4607-a78f-d903506a23bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# query\n",
    "x = index.similarity_search(columns=[\"text\"],\n",
    "                    query_text=\"Represent this sentence for searching relevant passages: What are the different methods for creating a vector search endpoint?\",\n",
    "                    num_results = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6591ca39-75fc-4519-ba8a-1403b45d0fe3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(x[\"result\"][\"data_array\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe104e9d-248d-4578-ad8f-c5c7c3d9e089",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 3. Putting them together: Vector Search + Foundation Model API\n",
    "- Raw results from the vector search are not very useful: they do not directly answer the user query and they may require searching the retrieved results\n",
    "- This is where the \"Generation\" part of RAG comes in. We combine Vector Search's dynamic information retrieval capabilities with LLMs' language aptitude to generate clear and cohensive answers informed by the retrieved information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23f49e93-d2d3-444b-b0ba-9cee53101d4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_genai_inference import ChatSession, Embedding\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "class RAG:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=\"databricks-dbrx-instruct\",\n",
    "        system_message=\"You are a helpful assistant. Answer the user's question. If context is provided, you must answer based on the context.\",\n",
    "        max_tokens=2048,\n",
    "        index_name=\"shared.hackathon_demo.vs_index\",\n",
    "        endpoint=\"rag_demo_endpoint\",\n",
    "    ):\n",
    "        self.chat_session = ChatSession(\n",
    "            model=model, system_message=system_message, max_tokens=max_tokens,\n",
    "        )\n",
    "        self.vsc = VectorSearchClient(disable_notice=True)\n",
    "        self.endpoint = endpoint\n",
    "        self.index_name = index_name\n",
    "\n",
    "    def query_index(self, query, num_results=3):\n",
    "        \"\"\"\n",
    "        Queries the vector search index to retrieve relevant passages based on the given query.\n",
    "        Returns the concatenated text of the retrieved passages.\n",
    "        \"\"\"\n",
    "        index = self.vsc.get_index(\n",
    "            endpoint_name=self.endpoint,\n",
    "            index_name=self.index_name,\n",
    "        )\n",
    "\n",
    "        query_resp = index.similarity_search(\n",
    "            query_text= \"Represent this sentence for searching relevant passages: \" + query,\n",
    "            columns=[\"text\"],\n",
    "            num_results=num_results,\n",
    "        )\n",
    "\n",
    "        results = query_resp[\"result\"][\"data_array\"]\n",
    "        concatenated_text = \"\"\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "            concatenated_text += result[0]  \n",
    "            if i < len(results) - 1:\n",
    "                concatenated_text += \"\\n---\\n\" \n",
    "\n",
    "        return concatenated_text\n",
    "\n",
    "    def query_rag(self, user_input):\n",
    "        \"\"\"\n",
    "        Performs Retrieval-Augmented Generation (RAG) using the provided user input.\n",
    "        Retrieves relevant context from the index and generates a response using the chat model.\n",
    "        \"\"\"\n",
    "        ctx_chunks = self.query_index(user_input)\n",
    "        ctx = (\n",
    "            \"Answer the question based on the provided context. Context:\\n\\n\"\n",
    "            + ctx_chunks\n",
    "            + \"\\n\\n\"\n",
    "        )\n",
    "        self.chat_session.reply(ctx + '\\n\\n' + user_input)\n",
    "        bot_response = self.chat_session.last.strip()\n",
    "        return bot_response\n",
    "\n",
    "    def clear_chat(self):\n",
    "        \"\"\"Clears the chat session history.\"\"\"\n",
    "        self.chat_session.history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46a94998-f360-40a3-bb29-054506227db7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8d426a-f8e6-4b31-bd66-f23c3789408b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(rag.query_rag(\"What are the different ways I can create a vector search endpoint?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a82ff8-8c39-48d0-a822-ada1114c03ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(rag.query_rag(\"What is the difference between a delta sync index and a direct vector access index?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a94b4c83-1fcc-4899-b312-f0717b5e0e9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rag.clear_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "991509db-9cf8-41d9-ab06-a4375144e354",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(rag.query_rag(\"Give me python code to create a new continuous sync vector index called MY_INDEX on delta table MY_TABLE and endpoint MY_ENDPOINT using the python sdk. Use the databricks-bge-large-en embeddings model.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba0f25ca-bc60-4c95-8672-b4d624a0424f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Learn More\n",
    "\n",
    "https://notebooks.databricks.com/demos/llm-rag-chatbot/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe9ec2e-b615-49b5-ad46-ea285df4b97d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install dbdemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f35f02a6-0fbd-4081-a588-75ffdd14cad0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dbdemos\n",
    "dbdemos.install('llm-rag-chatbot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1e0506a-8bcd-428c-988d-a93a89b62a74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ec63da3-12d6-4899-aa27-bc5bf04ad7e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "truncate table shared.hackathon_demo.source_table;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3002431975466937,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "hackathon_demo_share (1)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
